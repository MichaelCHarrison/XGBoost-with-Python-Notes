{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Case Study: Encoding string target variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "data = read_csv(url, header = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into X/Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data.values[:,0:4]\n",
    "Y = data.values[:,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode String Class (target variable) as integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder = label_encoder.fit(Y)\n",
    "label_encoded_y = label_encoder.transform(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, label_encoded_y,\n",
    "                                                    test_size = 0.33, \n",
    "                                                    random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Model on Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='multi:softprob', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.00%\n"
     ]
    }
   ],
   "source": [
    "#Predict\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "#Evaluate\n",
    "accuracy = accuracy_score(Y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer Case Study: categorical datasets\n",
    "Some datasets only contain categorical data, for example the breast cancer dataset. This dataset describes the technical details of breast cancer biopsies and the prediction task is to predict whether or not the patient has a recurrence of cancer, or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from pandas import read_csv\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(286, 10)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'breastcancer.csv'\n",
    "data = read_csv(filename, header = None, delimiter=\",\", skiprows = 105, nrows = 286)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'40-49'</td>\n",
       "      <td>'premeno'</td>\n",
       "      <td>'15-19'</td>\n",
       "      <td>'0-2'</td>\n",
       "      <td>'yes'</td>\n",
       "      <td>'3'</td>\n",
       "      <td>'right'</td>\n",
       "      <td>'left_up'</td>\n",
       "      <td>'no'</td>\n",
       "      <td>'recurrence-events'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'50-59'</td>\n",
       "      <td>'ge40'</td>\n",
       "      <td>'15-19'</td>\n",
       "      <td>'0-2'</td>\n",
       "      <td>'no'</td>\n",
       "      <td>'1'</td>\n",
       "      <td>'right'</td>\n",
       "      <td>'central'</td>\n",
       "      <td>'no'</td>\n",
       "      <td>'no-recurrence-events'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'50-59'</td>\n",
       "      <td>'ge40'</td>\n",
       "      <td>'35-39'</td>\n",
       "      <td>'0-2'</td>\n",
       "      <td>'no'</td>\n",
       "      <td>'2'</td>\n",
       "      <td>'left'</td>\n",
       "      <td>'left_low'</td>\n",
       "      <td>'no'</td>\n",
       "      <td>'recurrence-events'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'40-49'</td>\n",
       "      <td>'premeno'</td>\n",
       "      <td>'35-39'</td>\n",
       "      <td>'0-2'</td>\n",
       "      <td>'yes'</td>\n",
       "      <td>'3'</td>\n",
       "      <td>'right'</td>\n",
       "      <td>'left_low'</td>\n",
       "      <td>'yes'</td>\n",
       "      <td>'no-recurrence-events'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'40-49'</td>\n",
       "      <td>'premeno'</td>\n",
       "      <td>'30-34'</td>\n",
       "      <td>'3-5'</td>\n",
       "      <td>'yes'</td>\n",
       "      <td>'2'</td>\n",
       "      <td>'left'</td>\n",
       "      <td>'right_up'</td>\n",
       "      <td>'no'</td>\n",
       "      <td>'recurrence-events'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0          1        2      3      4    5        6           7      8  \\\n",
       "0  '40-49'  'premeno'  '15-19'  '0-2'  'yes'  '3'  'right'   'left_up'   'no'   \n",
       "1  '50-59'     'ge40'  '15-19'  '0-2'   'no'  '1'  'right'   'central'   'no'   \n",
       "2  '50-59'     'ge40'  '35-39'  '0-2'   'no'  '2'   'left'  'left_low'   'no'   \n",
       "3  '40-49'  'premeno'  '35-39'  '0-2'  'yes'  '3'  'right'  'left_low'  'yes'   \n",
       "4  '40-49'  'premeno'  '30-34'  '3-5'  'yes'  '2'   'left'  'right_up'   'no'   \n",
       "\n",
       "                        9  \n",
       "0     'recurrence-events'  \n",
       "1  'no-recurrence-events'  \n",
       "2     'recurrence-events'  \n",
       "3  'no-recurrence-events'  \n",
       "4     'recurrence-events'  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    object\n",
       "1    object\n",
       "2    object\n",
       "3    object\n",
       "4    object\n",
       "5    object\n",
       "6    object\n",
       "7    object\n",
       "8    object\n",
       "9    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All 9 input variables are categorical and described in string format. The problem is a binary classification prediction problem and the output class values are also described in string format. They need to be encoded.\n",
    "\n",
    "XGBoost may assume that encoded integer values for each input variable have an ordinal relationship. For example that left-up encoded as 0 and left-low encoded as 1 for the breast-quad variable have a meaningful relationship as integers. In this case, this assumption is untrue. Instead, we must map these integer values onto new binary variables, one new variable for each categorical value.\n",
    "\n",
    "This can be modeled as 5 binary variables in a process called ONE HOT ENCODING using the OneHotEncoder class in sklearn. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: :  (286, 37)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from numpy import column_stack\n",
    "\n",
    "#Split input/target\n",
    "X = data.values[:,1:9]\n",
    "X = X.astype(str)\n",
    "Y = data.values[:,9]\n",
    "\n",
    "#Encode string input variables\n",
    "columns = []\n",
    "for i in range(0, X.shape[1]):\n",
    "    label_encoder = LabelEncoder()\n",
    "    feature = label_encoder.fit_transform(X[:,i])\n",
    "    feature = feature.reshape(X.shape[0], 1)\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    feature = onehot_encoder.fit_transform(feature)\n",
    "    columns.append(feature)\n",
    "\n",
    "#Collapse columns into array\n",
    "encoded_x = column_stack(columns)\n",
    "print(\"X shape: : \", encoded_x.shape)\n",
    "\n",
    "#Encode string target variable\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder = label_encoder.fit(Y)\n",
    "encoded_y = label_encoder.transform(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into Train/Test sets; fit model, predict and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
      "Accuracy: 71.58%\n"
     ]
    }
   ],
   "source": [
    "# Split Train/Test\n",
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(encoded_x, encoded_y, \n",
    "                                                   test_size = test_size, random_state = seed)\n",
    "\n",
    "# Fit Model\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "print(model)\n",
    "\n",
    "# Predict and Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(Y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Horse Colic case study: XGBoost Support for Missing Data\n",
    "XGBoost can automatically learn how to best handle missing data. In fact, XGBoost was designed to work with sparse data, like the one hot encoded data from the previous section, and missing data is handled the same way that sparse or zero values are handled, by minimizing the loss function.\n",
    "\n",
    "The Horse Colic dataset is a good example to demonstrate this capability as it contains a\n",
    "large percentage of missing data, approximately 30%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 28)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load Libraries\n",
    "from pandas import read_csv\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#Load Data\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/horse-colic/horse-colic.data\"\n",
    "data = read_csv(url, delim_whitespace = True, header = None)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0   1        2      3    4   5  6  7  8  9  ...     18    19 20    21 22 23  \\\n",
      "0  2   1   530101  38.50   66  28  3  3  ?  2 ...  45.00  8.40  ?     ?  2  2   \n",
      "1  1   1   534817   39.2   88  20  ?  ?  4  1 ...     50    85  2     2  3  2   \n",
      "2  2   1   530334  38.30   40  24  1  1  3  1 ...  33.00  6.70  ?     ?  1  2   \n",
      "3  1   9  5290409  39.10  164  84  4  1  6  2 ...  48.00  7.20  3  5.30  2  1   \n",
      "4  2   1   530255  37.30  104  35  ?  ?  6  2 ...  74.00  7.40  ?     ?  2  2   \n",
      "\n",
      "      24 25 26 27  \n",
      "0  11300  0  0  2  \n",
      "1   2208  0  0  2  \n",
      "2      0  0  0  1  \n",
      "3   2208  0  0  1  \n",
      "4   4300  0  0  2  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     object\n",
       "1      int64\n",
       "2      int64\n",
       "3     object\n",
       "4     object\n",
       "5     object\n",
       "6     object\n",
       "7     object\n",
       "8     object\n",
       "9     object\n",
       "10    object\n",
       "11    object\n",
       "12    object\n",
       "13    object\n",
       "14    object\n",
       "15    object\n",
       "16    object\n",
       "17    object\n",
       "18    object\n",
       "19    object\n",
       "20    object\n",
       "21    object\n",
       "22    object\n",
       "23     int64\n",
       "24     int64\n",
       "25     int64\n",
       "26     int64\n",
       "27     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
      "Accuracy: 83.84%\n"
     ]
    }
   ],
   "source": [
    "#Split X/Y\n",
    "X = data.values[:, 0:27]\n",
    "Y = data.values[:, 27]\n",
    "\n",
    "#Set Missing values to 0; convert columns to numeric\n",
    "X[X == '?'] = 0\n",
    "X = X.astype('float32')\n",
    "\n",
    "#Encode the target class as integers\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder = label_encoder.fit(Y)\n",
    "encoded_y = label_encoder.transform(Y)\n",
    "\n",
    "#Split Train/Test sets\n",
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, encoded_y, test_size = test_size, random_state = seed)\n",
    "\n",
    "#Fit model\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "print(model)\n",
    "\n",
    "#Predict\n",
    "pred_y = model.predict(X_test)\n",
    "predictions = [round(value) for value in pred_y]\n",
    "\n",
    "#Evaluate\n",
    "accuracy = accuracy_score(Y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marking missing values as NaN\n",
    "Doing this actually demonstrates a lift in accuracy for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
      "Accuracy: 84.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:2: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  from ipykernel import kernelapp as app\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:2: VisibleDeprecationWarning: using a boolean instead of an integer will result in an error in the future\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "#Set Missing values to 0; convert columns to numeric\n",
    "X[X == '?'] = numpy.nan\n",
    "X = X.astype('float32')\n",
    "\n",
    "#Encode the target class as integers\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder = label_encoder.fit(Y)\n",
    "encoded_y = label_encoder.transform(Y)\n",
    "\n",
    "#Split Train/Test sets\n",
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, encoded_y, test_size = test_size, random_state = seed)\n",
    "\n",
    "#Fit model\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "print(model)\n",
    "\n",
    "#Predict\n",
    "pred_y = model.predict(X_test)\n",
    "predictions = [round(value) for value in pred_y]\n",
    "\n",
    "#Evaluate\n",
    "accuracy = accuracy_score(Y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
      "Accuracy: 86.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:4: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:4: VisibleDeprecationWarning: using a boolean instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "#Set Missing values to 0; convert columns to numeric\n",
    "X[X == '?'] = numpy.nan\n",
    "X = X.astype('float32')\n",
    "\n",
    "#Impute Missing valuses \n",
    "imputer = Imputer()\n",
    "imputed_x = imputer.fit_transform(X)\n",
    "\n",
    "#Encode the target class as integers\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder = label_encoder.fit(Y)\n",
    "encoded_y = label_encoder.transform(Y)\n",
    "\n",
    "#Split Train/Test sets\n",
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(imputed_x, encoded_y, test_size = test_size, random_state = seed)\n",
    "\n",
    "#Fit model\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "print(model)\n",
    "\n",
    "#Predict\n",
    "pred_y = model.predict(X_test)\n",
    "predictions = [round(value) for value in pred_y]\n",
    "\n",
    "#Evaluate\n",
    "accuracy = accuracy_score(Y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
